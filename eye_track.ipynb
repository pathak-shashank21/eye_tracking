{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b16911-c804-40f2-93f1-9d8678602343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "# Initialize dlib's face detector (HOG-based) and facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b7d2301-6400-408f-84a6-967af71bb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture from the webcam\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4d932f-e69a-4157-adaa-a36f8ac129bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Detect faces in the grayscale frame\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m faces \u001b[38;5;241m=\u001b[39m detector(gray)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale (required for Dlib)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = detector(gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6c7da-c1c2-4671-9763-ba722404e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for face in faces:\n",
    "        # Determine the facial landmarks for the face region\n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = [(p.x, p.y) for p in landmarks.parts()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b3004-570f-49ea-8e1b-c0060edb5000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eye_coordinates(landmarks):\n",
    "    left_eye = landmarks[36:42]\n",
    "    right_eye = landmarks[42:48]\n",
    "    return left_eye, right_eye\n",
    "\n",
    "def eye_center(eye):\n",
    "    x = int(np.mean([point[0] for point in eye]))\n",
    "    y = int(np.mean([point[1] for point in eye]))\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6394a473-4c9e-4207-95cc-0135927047d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot open camera\n",
      "Failed to capture frame\n",
      "No gaze points captured\n",
      "Cannot read image from your_image.jpg\n",
      "No gaze points to display on the image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1103.426] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@1103.426] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@1103.434] global loadsave.cpp:241 findDecoder imread_('your_image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize dlib's face detector and facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Function to get the eye coordinates\n",
    "def get_eye_coordinates(landmarks):\n",
    "    left_eye = landmarks[36:42]\n",
    "    right_eye = landmarks[42:48]\n",
    "    return left_eye, right_eye\n",
    "\n",
    "# Function to calculate the center of the eye\n",
    "def eye_center(eye):\n",
    "    x = int(np.mean([point[0] for point in eye]))\n",
    "    y = int(np.mean([point[1] for point in eye]))\n",
    "    return x, y\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "gaze_points = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces detected\")\n",
    "        \n",
    "    for face in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(frame, (face.left(), face.top()), (face.right(), face.bottom()), (255, 0, 0), 2)\n",
    "        \n",
    "        landmarks = predictor(gray, face)\n",
    "        landmarks = [(p.x, p.y) for p in landmarks.parts()]\n",
    "\n",
    "        # Draw landmarks\n",
    "        for (x, y) in landmarks:\n",
    "            cv2.circle(frame, (x, y), 1, (255, 255, 0), -1)\n",
    "\n",
    "        left_eye, right_eye = get_eye_coordinates(landmarks)\n",
    "        left_eye_center = eye_center(left_eye)\n",
    "        right_eye_center = eye_center(right_eye)\n",
    "\n",
    "        gaze_points.append(left_eye_center)\n",
    "        gaze_points.append(right_eye_center)\n",
    "\n",
    "        # Draw eyes centers\n",
    "        cv2.circle(frame, left_eye_center, 3, (0, 255, 0), -1)\n",
    "        cv2.circle(frame, right_eye_center, 3, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:  # ESC key to break\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Check if gaze points were captured\n",
    "if gaze_points:\n",
    "    # Save gaze points to a CSV file\n",
    "    gaze_df = pd.DataFrame(gaze_points, columns=['x', 'y'])\n",
    "    gaze_df.to_csv('gaze_points.csv', index=False)\n",
    "    print(f\"Saved {len(gaze_points)} gaze points to gaze_points.csv\")\n",
    "else:\n",
    "    print(\"No gaze points captured\")\n",
    "\n",
    "# Load an image to map gaze points\n",
    "image_path = 'your_image.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(f\"Cannot read image from {image_path}\")\n",
    "    exit()\n",
    "\n",
    "# Draw gaze points on the image if there are any\n",
    "if gaze_points:\n",
    "    for point in gaze_points:\n",
    "        cv2.circle(image, point, 5, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"Gaze Points\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No gaze points to display on the image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5946931-2127-48d5-be5f-4630e0190074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@798.710] global loadsave.cpp:241 findDecoder imread_('your_image.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the image\u001b[39;00m\n\u001b[1;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Plot the gaze points on the image\u001b[39;00m\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load gaze points from the CSV file\n",
    "gaze_df = pd.read_csv('/home/boasp/Documents/Projects/eye_tracking/gaze_points.csv')\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('your_image.jpg')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot the gaze points on the image\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image_rgb)\n",
    "\n",
    "# Extract gaze points\n",
    "gaze_points = gaze_df.values\n",
    "x = gaze_points[:, 0]\n",
    "y = gaze_points[:, 1]\n",
    "\n",
    "plt.scatter(x, y, c='red', s=10)\n",
    "plt.title(\"Gaze Points on Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2633226-5457-467d-a3cf-60c8c2733d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a blank image with the same dimensions as the original\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m heatmap, xedges, yedges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram2d(x, y, bins\u001b[38;5;241m=\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot the heatmap\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a blank image with the same dimensions as the original\n",
    "heatmap, xedges, yedges = np.histogram2d(x, y, bins=(image.shape[1], image.shape[0]))\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image_rgb, extent=[0, image.shape[1], image.shape[0], 0])\n",
    "plt.imshow(heatmap.T, cmap='jet', alpha=0.5, extent=[0, image.shape[1], image.shape[0], 0])\n",
    "plt.title(\"Heatmap of Gaze Points\")\n",
    "plt.colorbar(label='Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5ea58b-9f27-4bc6-b21e-e6d0eb8f7e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
